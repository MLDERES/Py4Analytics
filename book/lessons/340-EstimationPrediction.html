
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Prediction and Estimation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Advanced Techniques" href="341-AdvancedTechniques.html" />
    <link rel="prev" title="Automobile Accidents" href="335-ClassificationSolutions.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Python For Analytics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-JupyterNotebooks.html">
   Welcome to Jupyter Notebooks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 1 - Python Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="05-PartOne.html">
   Part 1 - Basic Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="10-Introduction.html">
     Learning to program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="20-Flow_Control.html">
     Flow Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="30-Functions.html">
     Reusing Code
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="TryIt_Part1.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/10-Introduction-ex.html">
     Try it: Getting Started with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/30-Functions-ex.html">
     Try it: Functions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 2 - Working with Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="35-PartTwo.html">
   Part 2 - Intermediate Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="40-Object_Orientation.html">
     Namespace, Objective Orientation and Packaging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="50-Data_Manipulation.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="60-Web_Data.html">
     Getting Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="70-Getting_Web_Data.html">
     Gather data from the web
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="80-Database_Connections.html">
     Connecting to SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="90-Data_Visualization.html">
     Exploratory Data Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="TryIt_Part2.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/40-Object_Orientation-ex.html">
     Try it: Objects, Namespaces and Packages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/50-Data_Manipulation-ex.html">
     Try it: Manipulating Data With pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/60-Web_Data-ex.html">
     Try it: Working with common data formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/70-Getting_Web_Data-ex.html">
     Try it: Getting data from the web
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/80-Database_Connections-ex.html">
     Try-it: Connecting to a Database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/90-Data_Visualization-ex.html">
     Try it: Data Visualization
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Part 3
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="300-PartThree.html">
   Part 3 - Using Python for Machine Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="310-ExploratoryDataAnalysis.html">
     Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="311-OtherToolsForEDA.html">
     Other tools for Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="312-VisualizationSamples.html">
     Visualization Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="320-DataPreparation.html">
     Data Preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="330-Classification.html">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="335-ClassificationSolutions.html">
     Automobile Accidents
     <a id="auto-accidents">
     </a>
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Prediction and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="341-AdvancedTechniques.html">
     Advanced Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="342-Pipelines.html">
     Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="343-Ensembling.html">
     Ensembling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="345-EstimationPredictionExample.html">
     Predicting the price of used cars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="350-Unsupervised.html">
     Unsupervised Data Mining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="360-NeuralNetworks.html">
     Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="VisualizationSamples.html">
     Visualization Samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="TryIt_Part3.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercises/310-ExploratoryDataAnalysis-ex.html">
     Try It: Exploratory Data Analysis
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercises/Coding_Challenges.html">
   Coding Challenges
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/mlderes/Py4Analytics/main?urlpath=tree/book/lessons/340-EstimationPrediction.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://waltonhub.com/hub/user-redirect/git-pull?repo=https%3A//github.com/mlderes/Py4Analytics&urlpath=tree/Py4Analytics/book/lessons/340-EstimationPrediction.ipynb&branch=main"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/mlderes/Py4Analytics"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mlderes/Py4Analytics/issues/new?title=Issue%20on%20page%20%2Fbook/lessons/340-EstimationPrediction.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/book/lessons/340-EstimationPrediction.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Prediction and Estimation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-predictive-performance">
     Evaluating Predictive Performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiple-linear-regression">
     Multiple Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#medical-insurance-forecast">
     Medical Insurance Forecast
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#about-bmi">
       About BMI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformers">
     Transformers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-selection">
     Feature Selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparing-model-performance">
       Comparing model performance
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-available-prediction-or-estimation-algorithms">
   Other Available Prediction or Estimation Algorithms
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vector-machines">
     Support Vector Machines
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nearest-neighbors">
     Nearest Neighbors
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-trees">
     Decision Trees
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-datasets-suitable-for-regressions-tasks">
     Other datasets suitable for regressions tasks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Prediction and Estimation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Prediction and Estimation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-predictive-performance">
     Evaluating Predictive Performance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiple-linear-regression">
     Multiple Linear Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#medical-insurance-forecast">
     Medical Insurance Forecast
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#about-bmi">
       About BMI
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformers">
     Transformers
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-selection">
     Feature Selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparing-model-performance">
       Comparing model performance
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-available-prediction-or-estimation-algorithms">
   Other Available Prediction or Estimation Algorithms
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vector-machines">
     Support Vector Machines
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nearest-neighbors">
     Nearest Neighbors
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-trees">
     Decision Trees
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-datasets-suitable-for-regressions-tasks">
     Other datasets suitable for regressions tasks
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span> <span class="k">as</span> <span class="n">MAE</span><span class="p">,</span> <span class="n">mean_absolute_percentage_error</span> <span class="k">as</span> <span class="n">MAPE</span><span class="p">,</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">MSE</span> 
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">src.data</span> <span class="kn">import</span> <span class="n">load_data</span>
<span class="kn">from</span> <span class="nn">src.metric</span> <span class="kn">import</span> <span class="n">regressionSummary</span><span class="p">,</span><span class="n">adjusted_r2_score</span><span class="p">,</span> <span class="n">AIC_score</span><span class="p">,</span> <span class="n">BIC_score</span>
<span class="kn">from</span> <span class="nn">src.feature_selection</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">exhaustive_search</span><span class="p">,</span> 
    <span class="n">backward_elimination</span><span class="p">,</span> 
    <span class="n">forward_selection</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pprint</span> <span class="k">as</span> <span class="nn">pp</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.precision&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="prediction-and-estimation">
<h1>Prediction and Estimation<a class="headerlink" href="#prediction-and-estimation" title="Permalink to this headline">#</a></h1>
<p>Estimation is about finding a model that explains existing data as well as possible, while predictive models are best when they can determine unknown values given the independent factors.</p>
<section id="evaluating-predictive-performance">
<h2>Evaluating Predictive Performance<a class="headerlink" href="#evaluating-predictive-performance" title="Permalink to this headline">#</a></h2>
<p>Evaluating performance of predictive or estimation models which use continuous targets uses a different technique than quantifying error rates.  Predictions are not simply correct or incorrect, but we can decide how close we were in our prediction or how far away.  A few techniques to determine performance of continuous target predictions include:</p>
<ul class="simple">
<li><p>Mean Error - the average difference between the predicted and expected target</p>
<ul>
<li><p>Valuable if the direction of the prediction is important (too high or too low) though it can be misleading since too-high and too-low can cancel each other out.</p></li>
</ul>
</li>
<li><p>MAE - Mean absolute error - the average difference between the predicted and expected target not accounting for sign
(+/-)</p>
<ul>
<li><p>takes the too high or too low issue out of play</p></li>
</ul>
</li>
<li><p>MPE - Mean percentage error - average percentage difference between predicted and expected target</p></li>
<li><p>MAPE - Mean absolute percentage error - average percentage difference between predicted and expected target (using absolute values rather than positive or negative error)</p></li>
<li><p>MSE - Mean square error - average of the square of the error of each prediction</p>
<ul>
<li><p>penalizes significant outliers and removes units so it is a relative metric only</p></li>
</ul>
</li>
<li><p>RMSE - Root mean square error - square root of the average of the square of the error of each prediction (provides relative units)</p>
<ul>
<li><p>still significantly penalizes bigger errors but also provides units of the base metric</p></li>
</ul>
</li>
</ul>
</section>
<section id="multiple-linear-regression">
<h2>Multiple Linear Regression<a class="headerlink" href="#multiple-linear-regression" title="Permalink to this headline">#</a></h2>
<p>Linear regression models are a great model to explain a linear relationship between predictors and target variables (assuming a linear relationship exists).  They are easy to explain and have a built-in metric to identify the importance of each predictor.  Also, we can use this information to include just enough of the variables to accurately describe the target possibly reducing the complexity</p>
<p>With linear regression we are attempting to describe a target variable in terms of a set of coefficients in a linear equation such as:
$$Y = \beta_0+\beta_1X_1+\beta_2X_2 + … \beta_nX_n + \epsilon$$
where $\beta$ represents coefficients and $X$ are the predictive factors (independent variables) and $\epsilon$ is <em>noise</em> or <em>unexplainable</em> part.  Data is used to estimate the coefficients and quantify the noise.</p>
</section>
<section id="medical-insurance-forecast">
<h2>Medical Insurance Forecast<a class="headerlink" href="#medical-insurance-forecast" title="Permalink to this headline">#</a></h2>
<p>Insurance companies need to set the insurance premiums following the population trends despite having limited information about the insured population if they have to put themselves in a position to make profits. This makes it necessary to estimate the average medical care expenses based on trends in the population segments, such as smokers, drivers, etc</p>
<p><a class="reference external" href="../data/insurance.csv#insurance">data dictionary</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">insurance_df</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;insurance&#39;</span><span class="p">)</span>
<span class="c1"># Start with checking our the first few rows</span>
<span class="n">insurance_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need to let pandas know that we have categorical data in a couple columns</span>
<span class="n">insurance_df</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Categorize the columns</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span><span class="s1">&#39;smoker&#39;</span><span class="p">,</span><span class="s1">&#39;region&#39;</span><span class="p">]:</span>
    <span class="n">insurance_df</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">=</span><span class="n">insurance_df</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># What&#39;s the range of charges</span>
<span class="n">insurance_df</span><span class="o">.</span><span class="n">charges</span><span class="o">.</span><span class="n">hist</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">insurance_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;region&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;charges&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<section id="about-bmi">
<h3>About BMI<a class="headerlink" href="#about-bmi" title="Permalink to this headline">#</a></h3>
<p>The CDC has the following <a class="reference external" href="(%5Bhttps://www.cdc.gov/obesity/adult/defining.html#:~:text=Adult%20Body%20Mass%20Index%20%28BMI%29%20%20%20,%20%20Obesity%20%201%20more%20rows%20)">guidance</a> with regard to interpreting BMI:</p>
<blockquote>
<div><ul class="simple">
<li><p>If your BMI is less than 18.5, it falls within the underweight range.</p></li>
<li><p>If your BMI is 18.5 to &lt;25, it falls within the healthy weight range.</p></li>
<li><p>If your BMI is 25.0 to &lt;30, it falls within the overweight range.</p></li>
<li><p>If your BMI is 30.0 or higher, it falls within the obesity range.</p></li>
</ul>
</div></blockquote>
<p>It seems like a good idea to build categories for these values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the categories for BMI based on CDC guidance</span>
<span class="n">insurance_df</span><span class="p">[</span><span class="s1">&#39;bmi_cat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">insurance_df</span><span class="o">.</span><span class="n">bmi</span><span class="p">,</span>
    <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">18.5</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;underweight&#39;</span><span class="p">,</span><span class="s1">&#39;healthy&#39;</span><span class="p">,</span><span class="s1">&#39;overweight&#39;</span><span class="p">,</span><span class="s1">&#39;obese&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now let&#39;s take a look to see if this plays a role</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">insurance_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;bmi_cat&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;charges&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>We are seeing exactly what we suspect that individuals that are overweight or obese are more likely to cause the insurance company more.  We could quanitify it as well</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># What&#39;s the actual difference in average cost</span>
<span class="n">insurance_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;bmi_cat&#39;</span><span class="p">)[</span><span class="s1">&#39;charges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>You may want to do some more digging into the data or creating some other new factors to help determine if we can find a good predictive model.  We’ll use what we have here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need to ensure that our data is &#39;encoded&#39; to work with the linear model</span>
<span class="n">num_columns</span><span class="o">=</span><span class="n">insurance_df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;number&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
<span class="n">cat_columns</span><span class="o">=</span><span class="n">insurance_df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;number&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
<span class="n">num_columns</span>
<span class="n">cat_columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_ins_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">insurance_df</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">cat_columns</span><span class="p">)</span>
<span class="n">new_ins_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">new_ins_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;charges&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_ins_df</span><span class="p">[</span><span class="s1">&#39;charges&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">regressionSummary</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="transformers">
<h2>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">#</a></h2>
<p>The sklearn library has standardized a set of transformers which we can use to apply to our data for preprocessing.  Just like in the last example where we had create the dummies and then scale the data, we can use a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html">column transformer</a> to apply a transformation to a particular column or set of columns.  Some helpful transformers that we will find useful like:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder">OneHotEncoder</a> for categorical data</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer">SimpleImputer</a> to help deal with missing data</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler">StandardScaler</a> for standardizing continuous features</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer">FunctionTransformer</a> when you need to apply a custom function to the data</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="c1"># Here we are going to apply two transforms to our numeric columns</span>
<span class="c1"># An imputer, to fill any gaps in our dataset with the median value</span>
<span class="c1"># And a scaler which we can use to ensure our data is standardized</span>
<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span> <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())]</span>
<span class="p">)</span>

<span class="c1"># For our categorical data, we&#39;ll use the OneHotEncoder</span>
<span class="c1">#  In essense this will dummy the columns for us</span>
<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="c1"># Here we define the transformers to use and which columns to apply them too</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;bmi&#39;</span><span class="p">,</span> <span class="s1">&#39;children&#39;</span><span class="p">],),</span>
        <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">cat_columns</span><span class="p">)],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load up the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">insurance_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;charges&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">insurance_df</span><span class="p">[</span><span class="s1">&#39;charges&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Keep in mind we need to apply the transform to both the train and the test sets.</span>
<span class="n">X_train_xform</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_xform</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Create a new regressor</span>
<span class="n">reg2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_xform</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_xform</span><span class="p">)</span>

<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">reg2</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">regressionSummary</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Not applying the same transform to the training data and test data can lead to disasterous consequences.  Fortunately we have a tool for this as well, pipelines.  Pipelines ensure that all the same transforms are applied to both the training and testing data.  There is a whole notebook on pipelines <a class="reference internal" href="342-Pipelines.html"><span class="doc std std-doc">here</span></a>.</p>
</section>
<section id="feature-selection">
<h2>Feature Selection<a class="headerlink" href="#feature-selection" title="Permalink to this headline">#</a></h2>
<p>Some Estimation and Prediction methods work just fine with a long list of features (and often prefer a larger set!).  For instance, Decision Trees self-select the best features based on how much additional information can be gained from splitting on a feature.  And neural networks were made for handling tons and tons of features.  Linear and Logistic regression (logistic regression is used for classification remember) often can have adequate models with less predictors.  Less predictors means less data and less processing, so it is advantageous to have as few predictors as possible for these algorithms.</p>
<p>Two approaches to stepwise feature selection in regression models:</p>
<ul class="simple">
<li><p>Forward Selection : start with no predictors and <em>add</em> one at a time until the accuracy doesn’t increase</p></li>
<li><p>Backward Selection : start with all the predictors and <em>remove</em> one at a time until the accuracy doesn’t increase</p></li>
</ul>
<p>Exhaustive searches are another option, where every combination of features is attempted, as are univariate and mutual information techniques.  Other approaches are covered in <a class="reference external" href="./41-AdvancedTechniques.ipynb#feature-reduction">another notebook</a></p>
<p>For this example we’ll use the Toyota Corolla dataset.  In this dataset, we will look at set of cars from a dealership looking to predict the value that they could get from a Corolla if they bought it on trade-in.  If they can sell a car for more than they bought it for they can make money.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reduce data frame to the top 1000 rows and select columns for regression analysis</span>
<span class="n">car_df</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;ToyotaCorolla&#39;</span><span class="p">)</span>
<span class="c1"># Just use the first 1000 rows</span>
<span class="n">car_df</span> <span class="o">=</span> <span class="n">car_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1000</span><span class="p">]</span>

<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age_08_04&#39;</span><span class="p">,</span> <span class="s1">&#39;KM&#39;</span><span class="p">,</span> <span class="s1">&#39;Fuel_Type&#39;</span><span class="p">,</span> <span class="s1">&#39;HP&#39;</span><span class="p">,</span> <span class="s1">&#39;Met_Color&#39;</span><span class="p">,</span> <span class="s1">&#39;Automatic&#39;</span><span class="p">,</span> <span class="s1">&#39;CC&#39;</span><span class="p">,</span> 
            <span class="s1">&#39;Doors&#39;</span><span class="p">,</span> <span class="s1">&#39;Quarterly_Tax&#39;</span><span class="p">,</span> <span class="s1">&#39;Weight&#39;</span><span class="p">]</span>
<span class="n">outcome</span> <span class="o">=</span> <span class="s1">&#39;Price&#39;</span>

<span class="c1"># partition data</span>
<span class="n">car_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">car_df</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">car_y</span> <span class="o">=</span> <span class="n">car_df</span><span class="p">[</span><span class="n">outcome</span><span class="p">]</span>
<span class="n">car_X_train</span><span class="p">,</span> <span class="n">car_X_test</span><span class="p">,</span> <span class="n">car_y_train</span><span class="p">,</span> <span class="n">car_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">car_X</span><span class="p">,</span> <span class="n">car_y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">car_lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">car_lm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">car_X_train</span><span class="p">,</span> <span class="n">car_y_train</span><span class="p">)</span>

<span class="c1"># print coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept &#39;</span><span class="p">,</span> <span class="n">car_lm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">car_X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">car_lm</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># print performance measures</span>
<span class="n">car_y_pred</span> <span class="o">=</span> <span class="n">car_lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">car_X_test</span><span class="p">)</span>
<span class="n">regressionSummary</span><span class="p">(</span><span class="n">car_y_test</span><span class="p">,</span> <span class="n">car_y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">car_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Predicted&#39;</span><span class="p">:</span><span class="n">car_y_pred</span><span class="p">,</span> <span class="s1">&#39;Actual&#39;</span><span class="p">:</span><span class="n">car_y_test</span><span class="p">,</span> <span class="s1">&#39;Residual&#39;</span><span class="p">:</span><span class="n">car_y_pred</span> <span class="o">-</span> <span class="n">car_y_test</span><span class="p">})</span>
<span class="n">car_results</span><span class="o">.</span><span class="n">Residual</span><span class="o">.</span><span class="n">hist</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<section id="comparing-model-performance">
<h3>Comparing model performance<a class="headerlink" href="#comparing-model-performance" title="Permalink to this headline">#</a></h3>
<p>Since we are about to reduce the number of predictors, we need to decide what is the best set of predictors.  One way to compare models of course is just to look at the outcomes and see which is best, but this can be misleading.  Several criteria for evaluating and comparing models are based on metrics computed from training data alone.  One popular method is <em>adjusted</em> $R^2$.  This is defined as
$$R^2_{adj}=1-\frac{n-1}{n-p-1}(1-R^2)$$
where $R^2$ is the proportion of variance explained by by a single predictor, <em>n</em> represents the number of observations and <em>p</em> is the number of predictors.  A higher $R^2$ means more variance from a single predictor.  But if we use an adjusted score because otherwise we would automatically get higher scores simply by adding more predictors.  There are other approaches as well <a class="reference external" href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC</a>.  In each case a higher value means a better set of predictors.  Since they all produce the same outcomes, we’ll show the values, but not go into the formulas</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Just to ensure we have a clean dataset to work with</span>
<span class="n">car_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">car_df</span><span class="p">[</span><span class="n">predictors</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">car_y</span> <span class="o">=</span> <span class="n">car_df</span><span class="p">[</span><span class="n">outcome</span><span class="p">]</span>
<span class="n">car_X_train</span><span class="p">,</span> <span class="n">car_X_test</span><span class="p">,</span> <span class="n">car_y_train</span><span class="p">,</span> <span class="n">car_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">car_X</span><span class="p">,</span> <span class="n">car_y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">variables</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">car_X_train</span><span class="p">[</span><span class="n">variables</span><span class="p">],</span> <span class="n">car_y_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">score_model_r2</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">variables</span><span class="p">):</span>
    <span class="n">pred_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">car_X_test</span><span class="p">[</span><span class="n">variables</span><span class="p">])</span>
    <span class="c1"># we negate as score is optimized to be as low as possible</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">adjusted_r2_score</span><span class="p">(</span><span class="n">car_y_test</span><span class="p">,</span> <span class="n">pred_y</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">score_model_AIC</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">variables</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">AIC_score</span><span class="p">(</span><span class="n">car_y_train</span><span class="p">,</span> <span class="p">[</span><span class="n">car_y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">car_y_train</span><span class="p">),</span> <span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">AIC_score</span><span class="p">(</span><span class="n">car_y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">car_X_train</span><span class="p">[</span><span class="n">variables</span><span class="p">]),</span> <span class="n">model</span><span class="p">)</span>


<span class="c1"># Let&#39;s try to do a model by looking at all the variable combinations</span>
<span class="n">allVariables</span> <span class="o">=</span> <span class="n">car_X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">exhaustive_search</span><span class="p">(</span><span class="n">allVariables</span><span class="p">,</span> <span class="n">train_model</span><span class="p">,</span> <span class="n">score_model_r2</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;variables&#39;</span><span class="p">]</span>
    <span class="n">AIC</span> <span class="o">=</span> <span class="n">AIC_score</span><span class="p">(</span><span class="n">car_y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">car_X_train</span><span class="p">[</span><span class="n">variables</span><span class="p">]),</span> <span class="n">model</span><span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n&#39;</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">],</span> <span class="s1">&#39;r2adj&#39;</span><span class="p">:</span> <span class="o">-</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="s1">&#39;AIC&#39;</span><span class="p">:</span> <span class="n">AIC</span><span class="p">}</span>
    <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">var</span><span class="p">:</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;variables&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">allVariables</span><span class="p">})</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;r2adj&#39;</span><span class="p">,</span> <span class="s1">&#39;AIC&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">allVariables</span><span class="p">))))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Backward elimination</span>
<span class="n">best_model</span><span class="p">,</span> <span class="n">best_variables</span> <span class="o">=</span> <span class="n">backward_elimination</span><span class="p">(</span>
    <span class="n">car_X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">train_model</span><span class="p">,</span> <span class="n">score_model_r2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">best_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Forward Selection</span>
<span class="c1"># The initial model is the constant model (that is no variables) - this requires special handling</span>
<span class="c1"># in train_model and score_model</span>

<span class="n">best_model</span><span class="p">,</span> <span class="n">best_variables</span> <span class="o">=</span> <span class="n">forward_selection</span><span class="p">(</span>
    <span class="n">car_X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">train_model</span><span class="p">,</span> <span class="n">score_model_AIC</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">best_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>While it is great that we know how to do this variable selection, it would be helpful if we could combine our knowledge and have a transformer to do the work for us.  Fortunately, the sklearn library has this on offer.  We have several variable selection techniques available and we can use what we know about.  If you are unfamiliar with Pipelines now would be a good opportunity to go <a class="reference internal" href="342-Pipelines.html"><span class="doc std std-doc">review the notebook</span></a> on these first.</p>
<p>Often our pipeline looks something like</p>
<style>
.center
{
    display:block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
}
</style>
<img src='../img/MLPipeline.png' width=400 height=300 class='center'/>
Putting this together with our Toyota cars dataset we can see how this improves (or not) our model<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SequentialFeatureSelector</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span><span class="p">,</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>

<span class="c1"># Reduce data frame to the top 1000 rows and select columns for regression analysis</span>
<span class="n">toyota_df</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;ToyotaCorolla&#39;</span><span class="p">,</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
            <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Age_08_04&#39;</span><span class="p">,</span> <span class="s1">&#39;KM&#39;</span><span class="p">,</span> <span class="s1">&#39;Fuel_Type&#39;</span><span class="p">,</span> <span class="s1">&#39;HP&#39;</span><span class="p">,</span> <span class="s1">&#39;Met_Color&#39;</span><span class="p">,</span> <span class="s1">&#39;Automatic&#39;</span><span class="p">,</span> <span class="s1">&#39;CC&#39;</span><span class="p">,</span> <span class="s1">&#39;Doors&#39;</span><span class="p">,</span> <span class="s1">&#39;Quarterly_Tax&#39;</span><span class="p">,</span> <span class="s1">&#39;Weight&#39;</span><span class="p">,</span> <span class="s1">&#39;Price&#39;</span><span class="p">])</span>

<span class="n">outcome</span> <span class="o">=</span> <span class="s1">&#39;Price&#39;</span>

<span class="n">num_columns</span> <span class="o">=</span> <span class="n">toyota_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">outcome</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;number&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
<span class="n">cat_columns</span> <span class="o">=</span> <span class="n">toyota_df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="s2">&quot;number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># Here we are going to apply two transforms to our numeric columns</span>
<span class="c1"># An imputer, to fill any gaps in our dataset with the median value</span>
<span class="c1"># And a scaler which we can use to ensure our data is standardized</span>
<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span> <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())]</span>
<span class="p">)</span>

<span class="c1"># For our categorical data, we&#39;ll use the OneHotEncoder</span>
<span class="c1">#  In essense this will dummy the columns for us</span>
<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">column_transformer</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">num_columns</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">cat_columns</span><span class="p">)])</span>

<span class="n">toyota_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Here we define the transformers to use and which columns to apply them too</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;col_transform&quot;</span><span class="p">,</span><span class="n">column_transformer</span><span class="p">)</span>
            <span class="p">,</span> <span class="p">(</span><span class="s2">&quot;feature_selection&quot;</span><span class="p">,</span><span class="n">SelectKBest</span><span class="p">())</span>
            <span class="p">,</span> <span class="p">(</span><span class="s1">&#39;regression_model&#39;</span><span class="p">,</span><span class="n">toyota_reg</span><span class="p">)])</span>
<span class="n">pipeline</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># And then, since we have our pipeline ready to go</span>
<span class="n">toyota_X</span> <span class="o">=</span> <span class="n">toyota_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">outcome</span><span class="p">)</span>
<span class="n">toyota_y</span> <span class="o">=</span> <span class="n">toyota_df</span><span class="p">[</span><span class="n">outcome</span><span class="p">]</span>

<span class="n">toyota_X_train</span><span class="p">,</span> <span class="n">toyota_X_test</span><span class="p">,</span> <span class="n">toyota_y_train</span><span class="p">,</span> <span class="n">toyota_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">toyota_X</span><span class="p">,</span><span class="n">toyota_y</span><span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">toyota_X_train</span><span class="p">,</span><span class="n">toyota_y_train</span><span class="p">)</span>
<span class="n">toyota_y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">toyota_X_test</span><span class="p">)</span>
<span class="n">regressionSummary</span><span class="p">(</span><span class="n">toyota_y_test</span><span class="p">,</span> <span class="n">toyota_y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="other-available-prediction-or-estimation-algorithms">
<h1>Other Available Prediction or Estimation Algorithms<a class="headerlink" href="#other-available-prediction-or-estimation-algorithms" title="Permalink to this headline">#</a></h1>
<p>The same techniques apply when using any other prediction and estimation algorithm from the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> library.  The data is prepared, split, fit and then predicted.</p>
<p>The following are a few other algorithm types (of which there are many deratives).</p>
<section id="support-vector-machines">
<h2>Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">#</a></h2>
<p>(from <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#svm-regression">scikit-learning</a>)
<br/>
Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.</p>
<p>The advantages of support vector machines are:
<br/></p>
<ul class="simple">
<li><p>Effective in high dimensional spaces.</p></li>
<li><p>Still effective in cases where number of dimensions is greater than the number of samples.</p></li>
<li><p>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</p></li>
<li><p>Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</p></li>
</ul>
<p>The disadvantages of support vector machines include:
<br/></p>
<ul class="simple">
<li><p>If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.</p></li>
<li><p>SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).</p></li>
</ul>
</section>
<section id="nearest-neighbors">
<h2>Nearest Neighbors<a class="headerlink" href="#nearest-neighbors" title="Permalink to this headline">#</a></h2>
<p>(from <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#classification">scikit-learning</a>)
<br/>
In the same way that Nearest Neighbors for classification attempts to find the other observations which have the most similar predictors, Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</p>
</section>
<section id="decision-trees">
<h2>Decision Trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">#</a></h2>
<p>(from <a class="reference external" href="https://scikit-learn.org/stable/modules/tree.html#tree">scikit-learning</a>)
<br/>
Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.</p>
<p>Some advantages of decision trees are:
<br/></p>
<ul class="simple">
<li><p>Simple to understand and to interpret. Trees can be visualised.</p></li>
<li><p>Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.</p></li>
<li><p>The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.</p></li>
<li><p>Able to handle both numerical and categorical data. However scikit-learn implementation does not support categorical variables for now. Other techniques are usually specialised in analysing datasets that have only one type of * variable. See algorithms for more information.</p></li>
<li><p>Able to handle multi-output problems.</p></li>
<li><p>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</p></li>
<li><p>Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.</p></li>
<li><p>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</p></li>
</ul>
<p>The disadvantages of decision trees include:</p>
<ul class="simple">
<li><p>Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning, setting the minimum number of samples required at a leaf node or setting the  maximum depth of the tree are necessary to avoid this problem.</p></li>
<li><p>Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated by using decision trees within an ensemble.</p></li>
<li><p>Predictions of decision trees are neither smooth nor continuous, but piecewise constant approximations as seen in the above figure. Therefore, they are not good at extrapolation.</p></li>
<li><p>The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic  algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.</p></li>
<li><p>There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.</p></li>
<li><p>Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="resources">
<h1>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">#</a></h1>
<section id="other-datasets-suitable-for-regressions-tasks">
<h2>Other datasets suitable for regressions tasks<a class="headerlink" href="#other-datasets-suitable-for-regressions-tasks" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><span class="xref myst">Boston Housing</span> - predict the mean value of a homes</p></li>
<li><p><span class="xref myst">Software Resale</span> - try to determine likely customer spend on software</p></li>
<li><p><span class="xref myst">Airfare</span> - predict the airfare for new routes</p></li>
<li><p><span class="xref myst">Cancer Death Rates</span> - see if there is a set of predictors that can identifier higher death rate due to cancer</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "mlderes/Py4Analytics",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./book/lessons"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="335-ClassificationSolutions.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Automobile Accidents <a id='auto-accidents'></a></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="341-AdvancedTechniques.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Advanced Techniques</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Michael Dereszynski<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>